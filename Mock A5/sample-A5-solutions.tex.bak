\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{enumitem}

\geometry{margin=1in}
\setlength{\parindent}{0pt}

\title{CS 338 - Spring 2025\\Assignment \#5 - Solutions}
\author{}
\date{}

\begin{document}

\maketitle

\section*{Question 1.}

\textbf{(a) Solution:}
READ COMMITTED. 1 read 1 write, no dirty reads.

\textbf{(b) Solution:}
REPEATABLE READ. 2 reads, read only, no dirty reads; Phantom allowed as not writing.

\textbf{(c) Solution:}
SERIALIZABLE. 3 reads, 1 write, no dirty reads.

\newpage
\section*{Question 2.}

\textbf{(a) Solution:}
With 1,000,000 records and 100 records per block, there are 10,000 disk blocks total.

For an unordered file with sequential search:
\begin{itemize}
    \item \textbf{Worst case:} 10,000 block accesses (record is in the last block or doesn't exist)
    \item \textbf{Average case:} 5,000 block accesses (record is found halfway through the file on average)
\end{itemize}


\textbf{(b) Solution:}
For an ordered file with binary search:
\begin{itemize}
    \item Number of blocks to search: $\log_2(10,000) \approx 14$ block accesses
    \item Both worst case and average case are approximately the same: 14 block accesses
\end{itemize}

This represents a significant improvement: from 5,000 average accesses to 14 accesses.\\


\textbf{(c) Solution:}
Index calculation:
\begin{itemize}
    \item Total index entries: 1,000,000
    \item Index entries per block: 500
    \item Total index blocks: 1,000,000 รท 500 = 2,000 blocks
\end{itemize}

Binary search on index blocks: $\log_2(2,000) \approx 11$ block accesses

Total access cost:
\begin{itemize}
    \item Index search: 11 block accesses
    \item Data record access: 1 block access
    \item \textbf{Total: 12 block accesses}
\end{itemize}


\textbf{(d) Solution:}
\textbf{Performance ranking (best to worst):}
1. Indexed file: 12 block accesses
2. Ordered file: 14 block accesses  
3. Unordered file: 5,000 block accesses (average)

\textbf{Indexed approach vs. Ordered file:}
\begin{itemize}
    \item \textbf{Advantage:} Slightly better search performance (12 vs 14 accesses) and easier insertion/deletion operations (no need to maintain physical order)
    \item \textbf{Disadvantage:} Additional storage overhead for the index (2,000 extra blocks) and increased complexity in maintaining the index during updates
\end{itemize}

\newpage
\section*{Question 3.}

\textbf{(a) Solution:}
\textbf{Minimum isolation level: SERIALIZABLE:} 2 read 2 write, no phantoms allowed. 1 read in \textbf{SELECT}, 1 read and 1 write in 
\textbf{UPDATE}, 1 write in \textbf{INSERT}\\
 
\textbf{(b) Solution:}\\

\textbf{Recommended indexes:}\\

\textbf{Book table:}

\begin{itemize}
    \item \texttt{CREATE UNIQUE INDEX idx\_book\_isbn ON Book(isbn);} - Primary access pattern, ensures uniqueness
    \item \texttt{CREATE INDEX idx\_book\_author ON Book(author);} - Frequent searches by author
    \item \texttt{CREATE INDEX idx\_book\_category ON Book(category);} - Moderate frequency, supports browsing
\end{itemize}

\textbf{Member table:}
\begin{itemize}
    \item \texttt{CREATE UNIQUE INDEX idx\_member\_id ON Member(member\_id);} - Primary key access
    \item \texttt{CREATE INDEX idx\_member\_email ON Member(email);} - Login functionality (assuming email-based login)
\end{itemize}

\textbf{Checkout table:}
\begin{itemize}
    \item \texttt{CREATE UNIQUE INDEX idx\_checkout\_id ON Checkout(checkout\_id);} - Primary key
    \item \texttt{CREATE INDEX idx\_checkout\_member ON Checkout(member\_id);} - Find member's checkout history
    \item \texttt{CREATE INDEX idx\_checkout\_isbn ON Checkout(isbn);} - Find checkout history for specific books
    \item \texttt{CREATE INDEX idx\_checkout\_returned ON Checkout(returned\_date);} - Find current checkouts (WHERE returned\_date IS NULL)
    \item \texttt{CREATE INDEX idx\_checkout\_due ON Checkout(due\_date);} - Find overdue books efficiently
\end{itemize}


\textbf{(c) Solution:}\\

\textbf{1. Isolation level: REPEATABLE READ}\\

The batch job needs consistent data throughout its execution but can tolerate new checkouts (phantoms) that occur during processing. REPEATABLE READ prevents the overdue status from changing during the job execution.\\

\textbf{2. Complete SQL query:}
\begin{verbatim}
-- Batch transaction for overdue books
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;

SELECT c.checkout_id, c.member_id, b.title, b.author, 
       m.name, m.email, c.checkout_date, c.due_date,
       CURRENT_DATE - c.due_date as days_overdue
FROM Checkout c
JOIN Book b ON c.isbn = b.isbn  
JOIN Member m ON c.member_id = m.member_id
WHERE c.returned_date IS NULL 
  AND c.due_date < CURRENT_DATE
ORDER BY c.due_date ASC;

COMMIT;
\end{verbatim}

\textbf{3. Handling concurrent returns:}
\begin{itemize}
    \item The REPEATABLE READ isolation level ensures that once the batch job starts, the set of overdue books remains consistent throughout the transaction
    \item Books returned after the batch job starts will still appear as overdue in this run, but will be excluded from the next day's batch
    \item This is acceptable behavior - it's better to send one extra reminder than to miss overdue books
    \item The \texttt{returned\_date IS NULL} condition, combined with REPEATABLE READ, ensures consistent results
    \item Alternative: Use a timestamp-based approach where the batch job processes books overdue as of a specific point in time
\end{itemize}

\end{document}
